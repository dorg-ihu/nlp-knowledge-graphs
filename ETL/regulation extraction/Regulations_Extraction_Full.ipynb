{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhBn94pQIsGE"
      },
      "source": [
        "#Connect to sharepoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQalnQXSIrTU",
        "outputId": "d0dfc454-6ff2-48e8-d1f3-b9185ddf47d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting office365\n",
            "  Downloading office365-0.3.15-py3-none-any.whl (32 kB)\n",
            "Collecting azure-storage-blob (from office365)\n",
            "  Downloading azure_storage_blob-12.17.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting O365 (from office365)\n",
            "  Downloading O365-2.0.27-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymiscutils (from office365)\n",
            "  Downloading pymiscutils-0.3.14-py3-none-any.whl (14 kB)\n",
            "Collecting pathmagic (from office365)\n",
            "  Downloading pathmagic-0.3.14-py3-none-any.whl (21 kB)\n",
            "Collecting pyiotools (from office365)\n",
            "  Downloading pyiotools-0.3.18-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysubtypes (from office365)\n",
            "  Downloading pysubtypes-0.3.18-py3-none-any.whl (31 kB)\n",
            "Collecting maybe-else (from office365)\n",
            "  Downloading maybe_else-0.2.1-py3-none-any.whl (5.5 kB)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob->office365)\n",
            "  Downloading azure_core-1.28.0-py3-none-any.whl (185 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.4/185.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/lib/python3/dist-packages (from azure-storage-blob->office365) (3.4.8)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->office365) (4.7.1)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob->office365)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from O365->office365) (2.27.1)\n",
            "Requirement already satisfied: requests-oauthlib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from O365->office365) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from O365->office365) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.5 in /usr/local/lib/python3.10/dist-packages (from O365->office365) (2022.7.1)\n",
            "Collecting tzlocal<5.0,>=4.0 (from O365->office365)\n",
            "  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from O365->office365) (4.11.2)\n",
            "Collecting stringcase>=1.2.0 (from O365->office365)\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pathmagic->office365) (1.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from pathmagic->office365) (8.4.0)\n",
            "Collecting PyPDF2 (from pathmagic->office365)\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pathmagic->office365) (1.4.4)\n",
            "Collecting bs4 (from pathmagic->office365)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill (from pathmagic->office365)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx (from pathmagic->office365)\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from pathmagic->office365) (1.0.3)\n",
            "Collecting pydub (from pathmagic->office365)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from pathmagic->office365) (1.8.2)\n",
            "Collecting simplejson (from pathmagic->office365)\n",
            "  Downloading simplejson-3.19.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting APScheduler (from pyiotools->office365)\n",
            "  Downloading APScheduler-3.10.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cursor (from pyiotools->office365)\n",
            "  Downloading cursor-1.3.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting readchar (from pyiotools->office365)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Collecting colorama (from pyiotools->office365)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting infi.systray (from pyiotools->office365)\n",
            "  Downloading infi.systray-0.1.12-py3-none-any.whl (9.2 kB)\n",
            "Collecting PyQt5 (from pyiotools->office365)\n",
            "  Downloading PyQt5-5.15.9-cp37-abi3-manylinux_2_17_x86_64.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typepy (from pyiotools->office365)\n",
            "  Downloading typepy-1.3.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pymiscutils->office365) (1.22.4)\n",
            "Collecting gender-guesser (from pymiscutils->office365)\n",
            "  Downloading gender_guesser-0.4.0-py2.py3-none-any.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.3/379.3 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyinstrument (from pymiscutils->office365)\n",
            "  Downloading pyinstrument-4.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.2/105.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum (from pysubtypes->office365)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting case-conversion (from pysubtypes->office365)\n",
            "  Downloading case_conversion-2.1.0.tar.gz (4.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colour (from pysubtypes->office365)\n",
            "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Collecting clipboard (from pysubtypes->office365)\n",
            "  Downloading clipboard-0.0.4.tar.gz (1.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting html-text (from pysubtypes->office365)\n",
            "  Downloading html_text-0.5.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting fuzzywuzzy (from pysubtypes->office365)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from pysubtypes->office365) (6.0.5)\n",
            "Collecting parsedatetime (from pysubtypes->office365)\n",
            "  Downloading parsedatetime-2.6-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prettierfier (from pysubtypes->office365)\n",
            "  Downloading prettierfier-1.0.3-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pysubtypes->office365) (2022.10.31)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pysubtypes->office365) (0.8.10)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pysubtypes->office365) (1.26.16)\n",
            "Collecting xlsxwriter (from pysubtypes->office365)\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msoffcrypto-tool (from pysubtypes->office365)\n",
            "  Downloading msoffcrypto_tool-5.1.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->office365) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.0.0->O365->office365) (2.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->O365->office365) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->O365->office365) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->O365->office365) (3.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=1.2.0->O365->office365) (3.2.2)\n",
            "Collecting pytz-deprecation-shim (from tzlocal<5.0,>=4.0->O365->office365)\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler->pyiotools->office365) (67.7.2)\n",
            "Collecting pyperclip>=1.3 (from clipboard->pysubtypes->office365)\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from html-text->pysubtypes->office365) (4.9.3)\n",
            "Requirement already satisfied: pydantic<2,>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->pysubtypes->office365) (1.10.11)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->pathmagic->office365) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->pathmagic->office365) (4.65.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->pathmagic->office365) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->pathmagic->office365) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->pathmagic->office365) (0.4.8)\n",
            "Collecting cryptography>=2.1.4 (from azure-storage-blob->office365)\n",
            "  Downloading cryptography-41.0.2-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from msoffcrypto-tool->pysubtypes->office365)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob->office365) (1.15.1)\n",
            "Collecting PyQt5-sip<13,>=12.11 (from PyQt5->pyiotools->office365)\n",
            "  Downloading PyQt5_sip-12.12.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (360 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.5/360.5 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyQt5-Qt5>=5.15.2 (from PyQt5->pyiotools->office365)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/83/d4/241a6a518d0bcf0a9fcdcbad5edfed18d43e884317eab8d5230a2b27e206/PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mbstrdecoder<2,>=1.0.0 (from typepy->pyiotools->office365)\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->office365) (2.21)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->typepy->pyiotools->office365) (4.0.0)\n",
            "Collecting tzdata (from pytz-deprecation-shim->tzlocal<5.0,>=4.0->O365->office365)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: stringcase, bs4, case-conversion, clipboard, cursor, python-docx, olefile, pyperclip\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3569 sha256=1cfef8b0ad72eaf9f2a1535b20db8e6378c802fe5b089fdf65936a7927a96889\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/ba/22/1a2d952a9ce8aa86e42fda41e2c87fdaf20e238c88bf8df013\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=f21734ff0148756ebc88e154c75c787fa3646e06c0238136f3d219d1e1cde664\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "  Building wheel for case-conversion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for case-conversion: filename=case_conversion-2.1.0-py3-none-any.whl size=5343 sha256=569a046e1e6570f081c215dccf1a82c76308648c439516f45fe16ae846d132a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/9c/c6/74b44af215cbc418a961c4de5002ecd5a719b57d5ceb341caa\n",
            "  Building wheel for clipboard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clipboard: filename=clipboard-0.0.4-py3-none-any.whl size=1849 sha256=9e52d42b2dc5a51a759fb94333ee5042029b669644214dd8b010ede98de4012f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/16/29/0b45762bf14ad4ba5495cd4ce66c7e326ecb0d5f1edeb7c94d\n",
            "  Building wheel for cursor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cursor: filename=cursor-1.3.5-py3-none-any.whl size=15821 sha256=1dfdc8b01ce8db1dab667c11633ac3bbff95daf375007bc2393712c224deaea7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/08/7f/46a8be2d2406ef8f31f519626da634ff35ad543bf5b2a77d95\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=7f4c8fc946a175d0307757a88e3285f0386217c040ec7ae6d25d5f61edd273a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=c6c43afc8cec4769559c32f94f80974a2f8b105b6d29b2559df7f78fc3e8bab9\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11124 sha256=e452408bd4e5e315c88b6de67cc6713c8de860eda0c6b834ab7cfecdbeccf14b\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/24/fe/140a94a7f1036003ede94579e6b4227fe96c840c6f4dcbe307\n",
            "Successfully built stringcase bs4 case-conversion clipboard cursor python-docx olefile pyperclip\n",
            "Installing collected packages: stringcase, PyQt5-Qt5, pyperclip, pydub, prettierfier, parsedatetime, maybe-else, gender-guesser, fuzzywuzzy, cursor, colour, aenum, xlsxwriter, tzdata, simplejson, readchar, python-docx, PyQt5-sip, PyPDF2, pyinstrument, olefile, mbstrdecoder, isodate, infi.systray, html-text, dill, colorama, clipboard, case-conversion, typepy, pytz-deprecation-shim, PyQt5, cryptography, bs4, azure-core, tzlocal, msoffcrypto-tool, azure-storage-blob, pysubtypes, O365, APScheduler, pathmagic, pymiscutils, pyiotools, office365\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 5.0.1\n",
            "    Uninstalling tzlocal-5.0.1:\n",
            "      Successfully uninstalled tzlocal-5.0.1\n",
            "Successfully installed APScheduler-3.10.1 O365-2.0.27 PyPDF2-3.0.1 PyQt5-5.15.9 PyQt5-Qt5-5.15.2 PyQt5-sip-12.12.1 aenum-3.1.15 azure-core-1.28.0 azure-storage-blob-12.17.0 bs4-0.0.1 case-conversion-2.1.0 clipboard-0.0.4 colorama-0.4.6 colour-0.1.5 cryptography-41.0.2 cursor-1.3.5 dill-0.3.6 fuzzywuzzy-0.18.0 gender-guesser-0.4.0 html-text-0.5.2 infi.systray-0.1.12 isodate-0.6.1 maybe-else-0.2.1 mbstrdecoder-1.1.3 msoffcrypto-tool-5.1.1 office365-0.3.15 olefile-0.46 parsedatetime-2.6 pathmagic-0.3.14 prettierfier-1.0.3 pydub-0.25.1 pyinstrument-4.5.0 pyiotools-0.3.18 pymiscutils-0.3.14 pyperclip-1.8.2 pysubtypes-0.3.18 python-docx-0.8.11 pytz-deprecation-shim-0.1.0.post0 readchar-4.0.5 simplejson-3.19.1 stringcase-1.2.0 typepy-1.3.1 tzdata-2023.3 tzlocal-4.3.1 xlsxwriter-3.1.2\n",
            "Collecting Office365-REST-Python-Client\n",
            "  Downloading Office365_REST_Python_Client-2.4.2-py3-none-any.whl (909 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m909.2/909.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Office365-REST-Python-Client) (2.27.1)\n",
            "Collecting msal (from Office365-REST-Python-Client)\n",
            "  Downloading msal-1.22.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from Office365-REST-Python-Client) (2022.7.1)\n",
            "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal->Office365-REST-Python-Client) (2.3.0)\n",
            "Requirement already satisfied: cryptography<43,>=0.6 in /usr/local/lib/python3.10/dist-packages (from msal->Office365-REST-Python-Client) (41.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Office365-REST-Python-Client) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Office365-REST-Python-Client) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->Office365-REST-Python-Client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Office365-REST-Python-Client) (3.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43,>=0.6->msal->Office365-REST-Python-Client) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43,>=0.6->msal->Office365-REST-Python-Client) (2.21)\n",
            "Installing collected packages: msal, Office365-REST-Python-Client\n",
            "Successfully installed Office365-REST-Python-Client-2.4.2 msal-1.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install office365\n",
        "!pip install Office365-REST-Python-Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2tzJmHIbJgEu"
      },
      "outputs": [],
      "source": [
        "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
        "from office365.sharepoint.client_context import ClientContext\n",
        "from office365.runtime.auth.client_credential import ClientCredential\n",
        "from office365.sharepoint.files.file import File\n",
        "\n",
        "####inputs########\n",
        "# This will be the URL that points to your sharepoint site.\n",
        "# Make sure you change only the parts of the link that start with \"Your\"\n",
        "url_shrpt = 'https://ihuedu.sharepoint.com/sites/EDYTEProject2023/'\n",
        "username_shrpt = '###############'\n",
        "password_shrpt = '###############'\n",
        "folder_files_url_shrpt = '/sites/EDYTEProject2023/Shared%20Documents/General/wp5_data/raw_Data/'\n",
        "folder_analysis_url_shrpt = '/sites/EDYTEProject2023/Shared%20Documents/General/wp5_data/analysis_exports/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4K68ElJJjZM",
        "outputId": "00aa9172-4368-48f9-9a10-209c7d69bf31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authenticated into sharepoint as:  EDYTE Project 2023\n"
          ]
        }
      ],
      "source": [
        "###Authentication###For authenticating into your sharepoint site###\n",
        "ctx_auth = AuthenticationContext(url_shrpt)\n",
        "if ctx_auth.acquire_token_for_user(username_shrpt, password_shrpt):\n",
        "  ctx = ClientContext(url_shrpt, ctx_auth)\n",
        "  web = ctx.web\n",
        "  ctx.load(web)\n",
        "  ctx.execute_query()\n",
        "  print('Authenticated into sharepoint as: ',web.properties['Title'])\n",
        "\n",
        "else:\n",
        "  print(ctx_auth.get_last_error())\n",
        "############################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07sdonESJlRD",
        "outputId": "78587fab-4e6a-4f7e-dede-49568d428c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['process-provision-digital-locations.csv', 'process-steps-digital.csv', 'process-steps.csv', 'process-evidences-cost.csv', 'process.csv', 'process-rules.csv', 'process-conditions.csv', 'process-evidences.csv']\n"
          ]
        }
      ],
      "source": [
        "####Function for extracting the file names of a folder in sharepoint###\n",
        "###If you want to extract the folder names instead of file names, you have to change \"sub_folders = folder.files\" to \"sub_folders = folder.folders\" in the below function\n",
        "\n",
        "global print_folder_contents\n",
        "def print_folder_contents(ctx, folder_url):\n",
        "    try:\n",
        "\n",
        "        folder = ctx.web.get_folder_by_server_relative_url(folder_url)\n",
        "        fold_names = []\n",
        "        sub_folders = folder.files #Replace files with folders for getting list of folders\n",
        "        ctx.load(sub_folders)\n",
        "        ctx.execute_query()\n",
        "\n",
        "        for s_folder in sub_folders:\n",
        "\n",
        "            fold_names.append(s_folder.properties[\"Name\"])\n",
        "\n",
        "        return fold_names\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Problem printing out library contents: ', e)\n",
        "######################################################\n",
        "\n",
        "# Call the function by giving your folder URL as input\n",
        "filelist_shrpt=print_folder_contents(ctx,folder_files_url_shrpt)\n",
        "#Print the list of files present in the folder\n",
        "print(filelist_shrpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKJGfWGvJoiO"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h12ri7KVJwjF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K8AWuZLlJ418"
      },
      "outputs": [],
      "source": [
        "def process_csv_file(file_name, column_names):\n",
        "    file_url= folder_files_url_shrpt+file_name\n",
        "    response = File.open_binary(ctx, file_url)  # Assuming File is imported and ctx is defined\n",
        "\n",
        "    df = pd.read_csv(io.BytesIO(response.content))\n",
        "    df = df.loc[:, column_names]\n",
        "    df = df.dropna(subset=column_names[-1])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tb2oSypkKkRi"
      },
      "outputs": [],
      "source": [
        "process_description = process_csv_file(\"process.csv\", ['id', 'title_el', 'description'])\n",
        "process_remarks = process_csv_file(\"process.csv\", ['id', 'title_el', 'remarks'])\n",
        "process_evidences = process_csv_file(\"process-evidences.csv\", ['process_id', 'evidence_num_id', 'ihu_unique_evidence_id', 'evidence_description'])\n",
        "process_conditions = process_csv_file(\"process-conditions.csv\", ['process_id', 'conditions_num_id', 'ihu_unique_condition_id', 'conditions_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0qp46zkZeGH"
      },
      "source": [
        "# Import Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LlL-2sLrZdWF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww6jfebGjs3e",
        "outputId": "ac7babbe-8147-4c59-e8a9-92cc241da583"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "greek_stopwords = stopwords.words('greek')\n",
        "\n",
        "new_words = ['της', 'τη', 'του', 'από', 'την', 'και', 'εώς', 'εως']\n",
        "\n",
        "for word in new_words:\n",
        "  greek_stopwords.append(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wg4Ltr7YaYQ"
      },
      "source": [
        "# Regulation Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E3JPcZ-3b3gu"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(regulation):\n",
        "  words = regulation.split()\n",
        "  regulation = ' '.join([word for word in words if word not in greek_stopwords])\n",
        "  return regulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_EKgCXqEhGhC"
      },
      "outputs": [],
      "source": [
        "def is_date(regulation):\n",
        "    # Check if the regulation is only a date\n",
        "    if re.match(r'\\d{1,2}\\/\\d{1,2}(?:\\/\\d{2,4})?', regulation):\n",
        "        return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QzjudDtgaIQ-"
      },
      "outputs": [],
      "source": [
        "def extract_regulations(df, column_name, id):\n",
        "\n",
        "    column = column_name\n",
        "    id = id\n",
        "    pattern = r'(\\S+\\s(?:\\d+\\/(?:\\d+(?:\\.\\d+)*(?:\\/\\d+(?:-\\d+)?)?)?(?:-\\d+)?))'\n",
        "\n",
        "    extracted_regulations = []\n",
        "\n",
        "    # Iterate over the 'step_description' column\n",
        "    for index, row in df.iterrows():\n",
        "        target_column = row[column]\n",
        "\n",
        "        # Use the pattern to extract regulations\n",
        "        matches = re.findall(pattern, target_column)\n",
        "\n",
        "        for regulation in matches:\n",
        "          regulation = remove_stopwords(regulation)\n",
        "          # Check if regulation is only a date after removing stopwords\n",
        "          if is_date(regulation):\n",
        "              continue\n",
        "\n",
        "          extracted_regulations.append({id: row[id], 'regulation': regulation})\n",
        "\n",
        "    results = pd.DataFrame(extracted_regulations)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W56O5xn7cpoT"
      },
      "source": [
        "#Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S4Y005zniupV"
      },
      "outputs": [],
      "source": [
        "results_process_description = extract_regulations(process_description, \"description\", \"id\")\n",
        "regulations_process_description = results_process_description.drop_duplicates()\n",
        "\n",
        "results_process_remarks = extract_regulations(process_remarks, \"remarks\", \"id\")\n",
        "regulations_process_remarks = results_process_remarks.drop_duplicates()\n",
        "\n",
        "\n",
        "results_process_evidences = extract_regulations(process_evidences, \"evidence_description\", \"ihu_unique_evidence_id\")\n",
        "regulations_process_evidences = results_process_evidences.drop_duplicates()\n",
        "\n",
        "\n",
        "results_process_conditions = extract_regulations(process_conditions, \"conditions_name\", \"ihu_unique_condition_id\")\n",
        "regulations_process_conditions = results_process_conditions.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5Vmj4H0xNnuu"
      },
      "outputs": [],
      "source": [
        "# Concatenate the data frames\n",
        "combined = pd.concat([regulations_process_description, regulations_process_remarks, regulations_process_evidences, regulations_process_conditions], ignore_index=True, sort=False)\n",
        "\n",
        "# Reorder the columns\n",
        "combined = combined[['id', 'ihu_unique_evidence_id', 'ihu_unique_condition_id', 'regulation']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sADckdWOeKj"
      },
      "source": [
        "# Assign ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D0-P3AYjNnDm"
      },
      "outputs": [],
      "source": [
        "def add_entity_ids(df):\n",
        "    # Extract unique keywords\n",
        "    keywords = set(df['regulation'])\n",
        "\n",
        "    # Assign IDs to keywords\n",
        "    keyword_ids = {keyword: i for i, keyword in enumerate(keywords, start=1)}\n",
        "\n",
        "    # Create the dictionary of unique keywords and IDs\n",
        "    keyword_dict = {keyword: keyword_ids[keyword] for keyword in keywords}\n",
        "\n",
        "    # Add the \"Entity ID\" column to the dataframe\n",
        "    df['Regulation ID'] = df['regulation'].apply(lambda x: keyword_ids[x])\n",
        "\n",
        "    return df, keyword_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cdr8Jr5Fj4T9"
      },
      "outputs": [],
      "source": [
        "final_regulations, regulations_dict = add_entity_ids(combined)\n",
        "final_regulations = final_regulations.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPSz3MiDs6gl",
        "outputId": "f589356f-97f1-413f-f1dd-dcfb31bd4fbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-40d0bb3f3f66>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_regulations['id'] = final_regulations['id'].apply(lambda x: str(int(x)) if not pd.isna(x) else x)\n"
          ]
        }
      ],
      "source": [
        "final_regulations['id'] = final_regulations['id'].apply(lambda x: str(int(x)) if not pd.isna(x) else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z1ArhIatjztf"
      },
      "outputs": [],
      "source": [
        "def upload_ids_to_target_folder(dic, name):\n",
        "\n",
        "  path = name+\".csv\"\n",
        "\n",
        "  # open file for writing, \"w\" is writing\n",
        "  w = csv.writer(open(path, \"w\"))\n",
        "\n",
        "  # loop over dictionary keys and values\n",
        "  for key, val in dic.items():\n",
        "\n",
        "      # write every key and value to file\n",
        "      w.writerow([key, val])\n",
        "\n",
        "  url=folder_analysis_url_shrpt+\"regulations_extraction\"\n",
        "  target_folder = ctx.web.get_folder_by_server_relative_url(url)\n",
        "\n",
        "  with open(path, \"rb\") as content_file:\n",
        "      file_content = content_file.read()\n",
        "      target_folder.upload_file(os.path.basename(path), file_content).execute_query()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hZTdH5nuj2FV"
      },
      "outputs": [],
      "source": [
        "upload_ids_to_target_folder(regulations_dict, \"regulations_dict\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txIarLbllIJg"
      },
      "source": [
        "split dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6KPW03lvlOrr"
      },
      "outputs": [],
      "source": [
        "def filter_dataframe_by_id(df, column_name):\n",
        "    filtered_df = df[df[column_name].notnull()]\n",
        "\n",
        "    # Select the desired columns for the new dataframe\n",
        "    selected_columns = [column_name, \"regulation\", \"Regulation ID\"]\n",
        "    new_df = filtered_df[selected_columns].reset_index(drop=True)\n",
        "\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pV5RugJcOmZ5"
      },
      "outputs": [],
      "source": [
        "def upload_entity_files_to_target_folder(unique_id, name):\n",
        "\n",
        "  result = filter_dataframe_by_id(final_regulations, unique_id)\n",
        "\n",
        "  path = name+\".csv\"\n",
        "\n",
        "  result.to_csv(path, index=False)\n",
        "\n",
        "  url=folder_analysis_url_shrpt+\"regulations_extraction\"\n",
        "  target_folder = ctx.web.get_folder_by_server_relative_url(url)\n",
        "  with open(path, \"rb\") as content_file:\n",
        "      file_content = content_file.read()\n",
        "      target_folder.upload_file(os.path.basename(path), file_content).execute_query()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nZ4gS5v1O8-l"
      },
      "outputs": [],
      "source": [
        "upload_entity_files_to_target_folder(\"id\", \"process_regulations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "L9oAgTpZpYhg"
      },
      "outputs": [],
      "source": [
        "upload_entity_files_to_target_folder(\"ihu_unique_evidence_id\", \"evidences_regulations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0wWXtBw2pbFE"
      },
      "outputs": [],
      "source": [
        "upload_entity_files_to_target_folder(\"ihu_unique_condition_id\", \"conditions_regulations\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "s0qp46zkZeGH",
        "1Wg4Ltr7YaYQ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
